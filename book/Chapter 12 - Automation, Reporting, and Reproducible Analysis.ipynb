{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1516dd",
   "metadata": {},
   "source": [
    "# Chapter 12 ‚Äî Automation, Reporting, and Reproducible Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand the importance of **automation** in data analytics workflows\n",
    "- Create **reusable functions** to automate repetitive analysis tasks\n",
    "- **Parameterize reports** so they can be run with different inputs\n",
    "- **Export results** to multiple formats (CSV, Excel, HTML, PDF)\n",
    "- Use **version control with Git** to track changes in your projects\n",
    "- Write **well-documented, readable code** that others can understand\n",
    "- Apply **reproducible research principles** to ensure your analysis can be replicated\n",
    "- **Schedule analytics tasks** to run automatically\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Why Automation Matters\n",
    "\n",
    "As a data analyst, you'll often find yourself repeating similar tasks:\n",
    "- Running the same analysis every week with new data\n",
    "- Generating reports for different regions, products, or time periods\n",
    "- Cleaning data the same way each time you receive an update\n",
    "\n",
    "**Manual repetition is:**\n",
    "- ‚è∞ **Time-consuming** ‚Äî you spend hours on tasks that could take seconds\n",
    "- ‚ùå **Error-prone** ‚Äî copy-paste mistakes, forgetting steps\n",
    "- üò¥ **Boring** ‚Äî tedious work leads to disengagement\n",
    "\n",
    "**Automation solves these problems by:**\n",
    "- ‚ö° **Saving time** ‚Äî run complex analyses with a single command\n",
    "- ‚úÖ **Reducing errors** ‚Äî code does the same thing every time\n",
    "- üìä **Enabling scale** ‚Äî generate 50 reports as easily as one\n",
    "- üîÑ **Ensuring consistency** ‚Äî every report follows the same process\n",
    "\n",
    "### What is Reproducible Analysis?\n",
    "\n",
    "**Reproducibility** means that someone else (or you, in 6 months) can:\n",
    "1. Take your code and data\n",
    "2. Run it exactly as you did\n",
    "3. Get the **same results**\n",
    "\n",
    "This is crucial for:\n",
    "- **Scientific credibility** ‚Äî others can verify your findings\n",
    "- **Collaboration** ‚Äî teammates can build on your work\n",
    "- **Debugging** ‚Äî you can trace exactly what happened\n",
    "\n",
    "> üí° **Tip:** Think of reproducibility as \"documentation for your future self.\" You *will* forget why you did something ‚Äî make it easy to remember!\n",
    "\n",
    "### Chapter Roadmap\n",
    "\n",
    "In this chapter, we'll build a complete **automated reporting pipeline** that:\n",
    "\n",
    "1. **Ingests** data (generates sample data for this demo)\n",
    "2. **Cleans** the data using reusable functions\n",
    "3. **Analyzes** by computing KPIs and breakdowns\n",
    "4. **Visualizes** with saved charts\n",
    "5. **Exports** to multiple formats (CSV, Excel, HTML)\n",
    "6. **Documents** with metadata for reproducibility\n",
    "\n",
    "Along the way, you'll learn best practices for code organization, version control, and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b9111",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.1 Setup and Environment\n",
    "\n",
    "### Required Libraries\n",
    "\n",
    "We'll use standard data analytics libraries:\n",
    "- **`pandas`** ‚Äî for data manipulation and tables\n",
    "- **`numpy`** ‚Äî for numeric operations and random data generation\n",
    "- **`matplotlib`** ‚Äî for creating and saving charts\n",
    "- **`pathlib`** ‚Äî for cross-platform file path handling (built into Python)\n",
    "\n",
    "> ‚ö†Ô∏è **Warning:** If Excel export fails later (missing `openpyxl` engine), we'll automatically fall back to CSV. You can install it with: `pip install openpyxl`\n",
    "\n",
    "### Setting Up Output Folders\n",
    "\n",
    "A key automation practice is **separating outputs from source code**. We'll save all generated files to an `outputs/chapter_12/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4778a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Setup: Import libraries and create output folder ===\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass          # For creating structured result objects\n",
    "from datetime import datetime, timedelta   # For timestamps and date math\n",
    "from pathlib import Path                   # Cross-platform file paths\n",
    "import json                                # For serializing parameters\n",
    "import platform                            # For recording system info\n",
    "import sys                                 # For Python version info\n",
    "\n",
    "import numpy as np                         # Numerical operations\n",
    "import pandas as pd                        # Data manipulation\n",
    "import matplotlib.pyplot as plt            # Visualization\n",
    "import seaborn as sns                      # Dataset loading and enhanced plots\n",
    "\n",
    "# Configure pandas display options for better readability\n",
    "pd.set_option(\"display.max_columns\", 50)   # Show more columns\n",
    "pd.set_option(\"display.width\", 120)        # Wider display\n",
    "\n",
    "# Create a dedicated output folder for this chapter\n",
    "# Using Path ensures this works on Windows, Mac, and Linux\n",
    "OUTPUT_ROOT = Path(\"outputs\") / \"chapter_12\"\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)  # Create if doesn't exist\n",
    "\n",
    "# Print environment info (useful for reproducibility)\n",
    "print(\"=\" * 50)\n",
    "print(\"ENVIRONMENT SETUP\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Output folder: {OUTPUT_ROOT.resolve()}\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160d439",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.2 Loading a Demo Dataset\n",
    "\n",
    "### Using Real Data from Seaborn\n",
    "\n",
    "Instead of generating synthetic data, we'll use the **taxis** dataset from seaborn ‚Äî a real-world dataset containing NYC taxi ride information. This is perfect for demonstrating automated reporting because it has:\n",
    "- Dates and times (for time-based aggregations)\n",
    "- Categorical variables (pickup/dropoff locations, payment type)\n",
    "- Numeric variables (distance, fare, tip)\n",
    "\n",
    "> üí° **Tip:** In real projects, you would load data from files, databases, or APIs. Using built-in datasets ensures this notebook works for everyone.\n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "The taxis dataset includes:\n",
    "- **pickup/dropoff** ‚Äî datetime and location information\n",
    "- **passengers** ‚Äî number of passengers\n",
    "- **distance** ‚Äî trip distance in miles\n",
    "- **fare** ‚Äî fare amount in dollars\n",
    "- **tip** ‚Äî tip amount\n",
    "- **payment** ‚Äî payment method (cash, credit card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036192c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sales_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and transform the seaborn taxis dataset for our sales reporting demo.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with columns: date, region, channel, product, quantity, unit_price\n",
    "    \"\"\"\n",
    "    # Load the taxis dataset from seaborn\n",
    "    taxis = sns.load_dataset(\"taxis\")\n",
    "    \n",
    "    # Transform to our \"sales\" format\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": pd.to_datetime(taxis[\"pickup\"]).dt.date,\n",
    "        \"region\": taxis[\"pickup_borough\"].fillna(\"Unknown\"),\n",
    "        \"channel\": taxis[\"payment\"].map({\"credit card\": \"Online\", \"cash\": \"Retail\"}).fillna(\"Partner\"),\n",
    "        \"product\": np.where(taxis[\"distance\"] > 5, \"Long Trip\", \n",
    "                   np.where(taxis[\"distance\"] > 2, \"Medium Trip\", \"Short Trip\")),\n",
    "        \"quantity\": taxis[\"passengers\"].fillna(1).astype(int).clip(1, 5),\n",
    "        \"unit_price\": taxis[\"fare\"].fillna(taxis[\"fare\"].median()).round(2)\n",
    "    })\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the raw data\n",
    "raw = load_sales_data()\n",
    "\n",
    "print(f\"Dataset shape: {raw.shape}\")\n",
    "print(f\"Date range: {raw['date'].min()} to {raw['date'].max()}\")\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e38af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.3 Automation in Analytics Workflows\n",
    "\n",
    "### The Automation Pattern\n",
    "\n",
    "A well-automated analytics workflow follows this pattern:\n",
    "\n",
    "```\n",
    "1. INGEST ‚Üí Load or generate data\n",
    "2. CLEAN ‚Üí Fix types, handle missing values, create derived columns  \n",
    "3. ANALYZE ‚Üí Compute KPIs, aggregations, breakdowns\n",
    "4. REPORT ‚Üí Export tables, charts, and formatted reports\n",
    "```\n",
    "\n",
    "Each step should be a **reusable function** that:\n",
    "- Takes inputs as parameters\n",
    "- Returns outputs explicitly\n",
    "- Has no hidden side effects\n",
    "- Can be tested independently\n",
    "\n",
    "> üí° **Tip:** Writing functions instead of loose code in cells makes your analysis:\n",
    "> - **Reusable** ‚Äî call the same function on different data\n",
    "> - **Testable** ‚Äî verify each piece works correctly\n",
    "> - **Readable** ‚Äî function names describe what they do\n",
    "\n",
    "### The Clean Step\n",
    "\n",
    "Let's implement data cleaning as a reusable function. This function:\n",
    "1. Converts columns to proper types\n",
    "2. Handles missing values\n",
    "3. Creates a new calculated column (`revenue`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa58662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sales_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean and prepare sales data for analysis.\n",
    "    \n",
    "    Steps performed:\n",
    "    1. Convert date column to datetime type\n",
    "    2. Convert text columns to string type\n",
    "    3. Fill missing prices with the median (simple imputation strategy)\n",
    "    4. Calculate revenue = quantity √ó unit_price\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Raw sales data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Cleaned sales data with 'revenue' column added\n",
    "    \"\"\"\n",
    "    # Always work on a copy to avoid modifying the original\n",
    "    cleaned = df.copy()\n",
    "    \n",
    "    # Step 1: Ensure date is proper datetime type\n",
    "    cleaned[\"date\"] = pd.to_datetime(cleaned[\"date\"], errors=\"coerce\")\n",
    "    \n",
    "    # Step 2: Convert text columns to string type for consistency\n",
    "    cleaned[\"region\"] = cleaned[\"region\"].astype(\"string\")\n",
    "    cleaned[\"channel\"] = cleaned[\"channel\"].astype(\"string\")\n",
    "    cleaned[\"product\"] = cleaned[\"product\"].astype(\"string\")\n",
    "    \n",
    "    # Step 3: Handle missing prices\n",
    "    # Using median is robust to outliers (better than mean for prices)\n",
    "    price_median = cleaned[\"unit_price\"].median(skipna=True)\n",
    "    missing_count = cleaned[\"unit_price\"].isna().sum()\n",
    "    cleaned[\"unit_price\"] = cleaned[\"unit_price\"].fillna(price_median)\n",
    "    print(f\"Filled {missing_count} missing prices with median: ${price_median:.2f}\")\n",
    "    \n",
    "    # Step 4: Calculate revenue\n",
    "    cleaned[\"revenue\"] = cleaned[\"quantity\"] * cleaned[\"unit_price\"]\n",
    "    \n",
    "    # Normalize dates (remove time component)\n",
    "    cleaned[\"date\"] = cleaned[\"date\"].dt.normalize()\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# Apply the cleaning function\n",
    "sales = clean_sales_data(raw)\n",
    "\n",
    "print(f\"\\nCleaned data shape: {sales.shape}\")\n",
    "print(f\"New columns: {set(sales.columns) - set(raw.columns)}\")\n",
    "print(f\"Revenue range: ${sales['revenue'].min():.2f} to ${sales['revenue'].max():.2f}\")\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6eef31",
   "metadata": {},
   "source": [
    "### üéØ Mini-Exercise 1: Improve the Cleaning Function\n",
    "\n",
    "The current cleaning function fills missing prices with the **overall median**. But different products might have very different prices!\n",
    "\n",
    "**Your task:** Modify the cleaning logic to fill missing prices with the **median price for that product**.\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint (click to expand)</summary>\n",
    "\n",
    "Use `groupby('product')['unit_price'].transform('median')` to get the per-product median for each row.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here:\n",
    "# Try modifying the clean_sales_data function to use per-product median\n",
    "\n",
    "# Example solution (uncomment to test):\n",
    "# def clean_sales_data_improved(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     cleaned = df.copy()\n",
    "#     cleaned[\"date\"] = pd.to_datetime(cleaned[\"date\"], errors=\"coerce\")\n",
    "#     # ... other type conversions ...\n",
    "#     \n",
    "#     # Per-product median imputation\n",
    "#     product_medians = cleaned.groupby(\"product\")[\"unit_price\"].transform(\"median\")\n",
    "#     cleaned[\"unit_price\"] = cleaned[\"unit_price\"].fillna(product_medians)\n",
    "#     \n",
    "#     cleaned[\"revenue\"] = cleaned[\"quantity\"] * cleaned[\"unit_price\"]\n",
    "#     return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e262f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.4 Parameterizing Reports\n",
    "\n",
    "### Why Parameters Matter\n",
    "\n",
    "Instead of hard-coding values like `region = \"North\"` scattered throughout your code, define **parameters** at the top of your script or notebook.\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Change one value, update the entire analysis\n",
    "- ‚úÖ Easy to run the same report for different inputs\n",
    "- ‚úÖ Clear documentation of what can be configured\n",
    "- ‚úÖ Enables command-line or scheduled execution\n",
    "\n",
    "> ‚ö†Ô∏è **Common Mistake:** Beginners often copy-paste code and change values in multiple places. This leads to bugs when you forget to update one location. **Always use parameters!**\n",
    "\n",
    "### Our Report Parameters\n",
    "\n",
    "For this demo report, we'll use two parameters:\n",
    "1. **`REPORT_REGION`** ‚Äî Which region to analyze (or \"ALL\" for everything)\n",
    "2. **`DAYS_LOOKBACK`** ‚Äî How many recent days to include\n",
    "\n",
    "Try changing these values and re-running the cells below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cbc66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# REPORT PARAMETERS - Change these to customize the report\n",
    "# ==========================================================\n",
    "\n",
    "REPORT_REGION = \"North\"     # Options: \"North\", \"South\", \"East\", \"West\", or \"ALL\"\n",
    "DAYS_LOOKBACK = 30          # Number of recent days to include (e.g., 7, 30, 90)\n",
    "\n",
    "# Display parameter summary\n",
    "print(\"=\" * 50)\n",
    "print(\"REPORT PARAMETERS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Region filter: {REPORT_REGION}\")\n",
    "print(f\"Days lookback: {DAYS_LOOKBACK}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nüí° Change these values and re-run to generate different reports!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc64c55",
   "metadata": {},
   "source": [
    "### Filtering Data Based on Parameters\n",
    "\n",
    "Now we create a function that applies our parameter filters. This function:\n",
    "1. Calculates the date range based on `days_lookback`\n",
    "2. Filters to the specified region (unless \"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0298624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_report(df: pd.DataFrame, region: str, days_lookback: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter data based on report parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Cleaned sales data\n",
    "    region : str\n",
    "        Region to filter by, or \"ALL\" for no region filter\n",
    "    days_lookback : int\n",
    "        Number of recent days to include\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Filtered data for the report\n",
    "    \"\"\"\n",
    "    # Calculate date range\n",
    "    end_date = df[\"date\"].max()\n",
    "    start_date = end_date - pd.Timedelta(days=days_lookback)\n",
    "    \n",
    "    # Filter by date\n",
    "    filtered = df[df[\"date\"].between(start_date, end_date)].copy()\n",
    "    print(f\"Date filter: {start_date.date()} to {end_date.date()}\")\n",
    "    print(f\"Rows after date filter: {len(filtered)}\")\n",
    "    \n",
    "    # Filter by region (unless \"ALL\")\n",
    "    if region.upper() != \"ALL\":\n",
    "        filtered = filtered[filtered[\"region\"] == region]\n",
    "        print(f\"Region filter: {region}\")\n",
    "        print(f\"Rows after region filter: {len(filtered)}\")\n",
    "    else:\n",
    "        print(\"Region filter: ALL (no filtering)\")\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "# Apply the filter\n",
    "report_df = filter_for_report(sales, REPORT_REGION, DAYS_LOOKBACK)\n",
    "\n",
    "print(f\"\\nFiltered data summary:\")\n",
    "print(f\"  Shape: {report_df.shape}\")\n",
    "print(f\"  Total revenue: ${report_df['revenue'].sum():,.2f}\")\n",
    "print(\"\\nPreview:\")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f4fbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.5 KPI Summary and Breakdowns\n",
    "\n",
    "### Understanding KPIs\n",
    "\n",
    "**KPIs (Key Performance Indicators)** answer the question: \"How are we doing overall?\"\n",
    "\n",
    "For a sales report, common KPIs include:\n",
    "- **Total Revenue** ‚Äî How much money did we make?\n",
    "- **Total Orders** ‚Äî How many transactions occurred?\n",
    "- **Total Units Sold** ‚Äî How many items were purchased?\n",
    "- **Average Order Value** ‚Äî How much is a typical order worth?\n",
    "\n",
    "### Understanding Breakdowns\n",
    "\n",
    "**Breakdowns** answer: \"Where is the performance coming from?\"\n",
    "\n",
    "They split KPIs by different dimensions:\n",
    "- By **channel** ‚Äî Are online sales growing faster than retail?\n",
    "- By **product** ‚Äî Which product generates the most revenue?\n",
    "- By **time** ‚Äî What's the daily trend?\n",
    "\n",
    "> ‚ö†Ô∏è **Common Mistake:** Mixing formatting (like `$1,234.56`) into your raw numbers too early. Keep numeric columns as numbers for calculations; format only at the final display step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate key performance indicators from sales data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Filtered sales data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Table with KPI names and values\n",
    "    \"\"\"\n",
    "    # Calculate each KPI\n",
    "    total_revenue = df[\"revenue\"].sum()\n",
    "    total_orders = len(df)\n",
    "    total_units = df[\"quantity\"].sum()\n",
    "    avg_order_value = total_revenue / total_orders if total_orders > 0 else 0\n",
    "    \n",
    "    # Return as a tidy table\n",
    "    return pd.DataFrame({\n",
    "        \"metric\": [\"total_revenue\", \"total_orders\", \"total_units\", \"avg_order_value\"],\n",
    "        \"value\": [total_revenue, total_orders, total_units, avg_order_value],\n",
    "    })\n",
    "\n",
    "\n",
    "# Calculate KPIs for our filtered data\n",
    "kpis = kpi_summary(report_df)\n",
    "\n",
    "# Display with formatting\n",
    "print(\"KPI Summary\")\n",
    "print(\"-\" * 40)\n",
    "for _, row in kpis.iterrows():\n",
    "    metric = row[\"metric\"]\n",
    "    value = row[\"value\"]\n",
    "    if \"revenue\" in metric or \"order_value\" in metric:\n",
    "        print(f\"{metric:20s}: ${value:,.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:20s}: {value:,.0f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "kpis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b3ac0",
   "metadata": {},
   "source": [
    "### Creating Breakdown Tables\n",
    "\n",
    "Now let's create functions to generate breakdown tables by channel, product, and date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_breakdowns(df: pd.DataFrame) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create breakdown tables by different dimensions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Filtered sales data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict[str, pd.DataFrame]\n",
    "        Dictionary with breakdown tables: by_channel, by_product, by_day\n",
    "    \"\"\"\n",
    "    # Breakdown by sales channel\n",
    "    by_channel = (\n",
    "        df.groupby(\"channel\", dropna=False)\n",
    "        .agg(\n",
    "            orders=(\"revenue\", \"size\"),      # Count of orders\n",
    "            revenue=(\"revenue\", \"sum\"),      # Total revenue\n",
    "            units=(\"quantity\", \"sum\")        # Total units\n",
    "        )\n",
    "        .sort_values(\"revenue\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Breakdown by product\n",
    "    by_product = (\n",
    "        df.groupby(\"product\", dropna=False)\n",
    "        .agg(\n",
    "            orders=(\"revenue\", \"size\"),\n",
    "            revenue=(\"revenue\", \"sum\"),\n",
    "            units=(\"quantity\", \"sum\")\n",
    "        )\n",
    "        .sort_values(\"revenue\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Breakdown by day (for trend analysis)\n",
    "    by_day = (\n",
    "        df.groupby(\"date\", dropna=False)\n",
    "        .agg(\n",
    "            orders=(\"revenue\", \"size\"),\n",
    "            revenue=(\"revenue\", \"sum\"),\n",
    "            units=(\"quantity\", \"sum\")\n",
    "        )\n",
    "        .sort_values(\"date\")  # Sort chronologically\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"by_channel\": by_channel,\n",
    "        \"by_product\": by_product,\n",
    "        \"by_day\": by_day\n",
    "    }\n",
    "\n",
    "\n",
    "# Generate breakdowns\n",
    "breakdowns = top_breakdowns(report_df)\n",
    "\n",
    "# Display results\n",
    "print(\"Revenue by Channel:\")\n",
    "print(breakdowns[\"by_channel\"].to_string(index=False))\n",
    "print(\"\\nRevenue by Product:\")\n",
    "print(breakdowns[\"by_product\"].to_string(index=False))\n",
    "print(f\"\\nDaily breakdown: {len(breakdowns['by_day'])} days of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce75ecb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.6 Generating Automated Reports with Charts\n",
    "\n",
    "### Why Save Charts as Files?\n",
    "\n",
    "Automation is most useful when it produces **artifacts** you can share:\n",
    "- üìä **PNG/JPG images** ‚Äî for presentations and emails\n",
    "- üìÑ **CSV/Excel files** ‚Äî for further analysis\n",
    "- üåê **HTML reports** ‚Äî for web viewing and sharing\n",
    "\n",
    "Charts saved as image files can be:\n",
    "- Embedded in reports and presentations\n",
    "- Attached to automated emails\n",
    "- Archived for historical comparison\n",
    "\n",
    "### Creating a Daily Revenue Chart\n",
    "\n",
    "Let's create a function that generates a chart and saves it as a PNG file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30235dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_daily_revenue_plot(by_day: pd.DataFrame, out_path: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Create and save a daily revenue chart.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    by_day : pd.DataFrame\n",
    "        Daily breakdown table with 'date' and 'revenue' columns\n",
    "    out_path : Path\n",
    "        Where to save the PNG file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Path\n",
    "        The path where the chart was saved\n",
    "    \"\"\"\n",
    "    # Create the figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Plot the data\n",
    "    ax.plot(\n",
    "        by_day[\"date\"], \n",
    "        by_day[\"revenue\"], \n",
    "        marker=\"o\",           # Circle markers at each point\n",
    "        linewidth=2,          # Line thickness\n",
    "        color=\"#2E86AB\",      # Professional blue color\n",
    "        markersize=6\n",
    "    )\n",
    "    \n",
    "    # Add styling\n",
    "    ax.set_title(\"Daily Revenue Trend\", fontsize=14, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Date\", fontsize=11)\n",
    "    ax.set_ylabel(\"Revenue ($)\", fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, linestyle=\"--\")\n",
    "    \n",
    "    # Format y-axis as currency\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "    \n",
    "    # Rotate x-axis labels for readability\n",
    "    fig.autofmt_xdate(rotation=30)\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.savefig(out_path, dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "    plt.close(fig)  # Close to free memory\n",
    "    \n",
    "    print(f\"‚úÖ Chart saved to: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# Save the chart\n",
    "chart_path = OUTPUT_ROOT / \"daily_revenue.png\"\n",
    "save_daily_revenue_plot(breakdowns[\"by_day\"], chart_path)\n",
    "\n",
    "# Display the chart inline as well\n",
    "from IPython.display import Image\n",
    "Image(filename=str(chart_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4406f5d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.7 Exporting Results (CSV, Excel, HTML)\n",
    "\n",
    "### Choosing Export Formats\n",
    "\n",
    "Different formats serve different purposes:\n",
    "\n",
    "| Format | Best For | Pros | Cons |\n",
    "|--------|----------|------|------|\n",
    "| **CSV** | Data exchange, archiving | Universal, simple, small | No formatting, one sheet |\n",
    "| **Excel** | Business users, multiple tables | Multiple sheets, formatting | Requires openpyxl library |\n",
    "| **HTML** | Web sharing, email | Opens in browser, embeds images | Larger files |\n",
    "| **PDF** | Formal reports, printing | Professional look, fixed layout | Harder to generate |\n",
    "\n",
    "### Export Strategy\n",
    "\n",
    "Our export function will:\n",
    "1. Try to save as Excel (multiple sheets in one file)\n",
    "2. Fall back to CSV if Excel library is missing\n",
    "3. Return a list of all files created\n",
    "\n",
    "> üí° **Tip:** Always use try/except when dealing with file operations. External libraries might not be installed, or disk might be full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ee0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_excel_or_csv(\n",
    "    out_dir: Path,\n",
    "    cleaned: pd.DataFrame,\n",
    "    kpis: pd.DataFrame,\n",
    "    breakdowns: dict[str, pd.DataFrame],\n",
    "    excel_name: str = \"report.xlsx\",\n",
    ") -> list[Path]:\n",
    "    \"\"\"\n",
    "    Export data to Excel (preferred) or CSV (fallback).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    out_dir : Path\n",
    "        Output directory\n",
    "    cleaned : pd.DataFrame\n",
    "        The cleaned data to export\n",
    "    kpis : pd.DataFrame\n",
    "        KPI summary table\n",
    "    breakdowns : dict[str, pd.DataFrame]\n",
    "        Breakdown tables by dimension\n",
    "    excel_name : str\n",
    "        Name for the Excel file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list[Path]\n",
    "        List of files that were created\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    written: list[Path] = []\n",
    "    excel_path = out_dir / excel_name\n",
    "    \n",
    "    # Try Excel first (requires openpyxl)\n",
    "    try:\n",
    "        with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "            cleaned.to_excel(writer, sheet_name=\"data\", index=False)\n",
    "            kpis.to_excel(writer, sheet_name=\"kpis\", index=False)\n",
    "            for name, table in breakdowns.items():\n",
    "                # Excel sheet names limited to 31 characters\n",
    "                table.to_excel(writer, sheet_name=name[:31], index=False)\n",
    "        \n",
    "        written.append(excel_path)\n",
    "        print(f\"‚úÖ Excel export successful: {excel_path.name}\")\n",
    "        return written\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Excel export failed: {e}\")\n",
    "        print(\"   Falling back to CSV files...\")\n",
    "    \n",
    "    # Fallback: Export as separate CSV files\n",
    "    csv_files = {\n",
    "        \"data.csv\": cleaned,\n",
    "        \"kpis.csv\": kpis,\n",
    "        **{f\"{name}.csv\": table for name, table in breakdowns.items()}\n",
    "    }\n",
    "    \n",
    "    for filename, df in csv_files.items():\n",
    "        path = out_dir / filename\n",
    "        df.to_csv(path, index=False)\n",
    "        written.append(path)\n",
    "        print(f\"‚úÖ Saved: {path.name}\")\n",
    "    \n",
    "    return written\n",
    "\n",
    "\n",
    "# Export the data\n",
    "export_paths = export_excel_or_csv(OUTPUT_ROOT, report_df, kpis, breakdowns)\n",
    "\n",
    "print(f\"\\nTotal files exported: {len(export_paths)}\")\n",
    "for p in export_paths:\n",
    "    print(f\"  üìÑ {p.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a1993",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.8 Generating HTML Reports\n",
    "\n",
    "### Why HTML Reports?\n",
    "\n",
    "HTML reports are powerful because:\n",
    "- üåê **Universal** ‚Äî Opens in any web browser\n",
    "- üìä **Rich content** ‚Äî Tables, images, styling all in one file\n",
    "- üìß **Shareable** ‚Äî Can be emailed or hosted on a server\n",
    "- üé® **Customizable** ‚Äî Full control over appearance with CSS\n",
    "\n",
    "### Building an HTML Report\n",
    "\n",
    "We'll create a function that:\n",
    "1. Converts DataFrames to HTML tables\n",
    "2. Embeds our saved chart image\n",
    "3. Adds a timestamp and styling\n",
    "4. Saves as a single HTML file\n",
    "\n",
    "> üí° **Tip:** For more complex reports, consider libraries like `Jinja2` (templating) or `weasyprint` (PDF generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967269f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_html_table(df: pd.DataFrame, max_rows: int = 20) -> str:\n",
    "    \"\"\"Convert a DataFrame to an HTML table string.\"\"\"\n",
    "    preview = df.head(max_rows)\n",
    "    return preview.to_html(index=False, escape=False, classes=\"data-table\")\n",
    "\n",
    "\n",
    "def export_html_report(\n",
    "    out_dir: Path,\n",
    "    title: str,\n",
    "    kpis: pd.DataFrame,\n",
    "    by_channel: pd.DataFrame,\n",
    "    by_product: pd.DataFrame,\n",
    "    chart_file: str,\n",
    "    report_name: str = \"report.html\",\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Generate a styled HTML report.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    out_dir : Path\n",
    "        Output directory\n",
    "    title : str\n",
    "        Report title\n",
    "    kpis : pd.DataFrame\n",
    "        KPI summary table\n",
    "    by_channel : pd.DataFrame\n",
    "        Channel breakdown\n",
    "    by_product : pd.DataFrame\n",
    "        Product breakdown\n",
    "    chart_file : str\n",
    "        Filename of the chart image (relative to report)\n",
    "    report_name : str\n",
    "        Output filename\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Path\n",
    "        Path to the generated HTML file\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    report_path = out_dir / report_name\n",
    "    \n",
    "    # HTML template with embedded CSS\n",
    "    html = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>{title}</title>\n",
    "    <style>\n",
    "        /* Reset and base styles */\n",
    "        * {{ box-sizing: border-box; }}\n",
    "        body {{\n",
    "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 24px;\n",
    "            background: #f8f9fa;\n",
    "            color: #333;\n",
    "            line-height: 1.6;\n",
    "        }}\n",
    "        \n",
    "        /* Container */\n",
    "        .container {{\n",
    "            max-width: 1000px;\n",
    "            margin: 0 auto;\n",
    "            background: white;\n",
    "            padding: 32px;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        \n",
    "        /* Typography */\n",
    "        h1 {{\n",
    "            color: #2c3e50;\n",
    "            border-bottom: 3px solid #3498db;\n",
    "            padding-bottom: 12px;\n",
    "            margin-top: 0;\n",
    "        }}\n",
    "        h2 {{\n",
    "            color: #34495e;\n",
    "            margin-top: 32px;\n",
    "        }}\n",
    "        \n",
    "        /* Metadata */\n",
    "        .meta {{\n",
    "            color: #7f8c8d;\n",
    "            font-size: 0.9em;\n",
    "            margin-bottom: 24px;\n",
    "        }}\n",
    "        \n",
    "        /* Tables */\n",
    "        .data-table {{\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "            margin: 16px 0 32px 0;\n",
    "        }}\n",
    "        .data-table th, .data-table td {{\n",
    "            border: 1px solid #ddd;\n",
    "            padding: 10px 12px;\n",
    "            text-align: left;\n",
    "        }}\n",
    "        .data-table th {{\n",
    "            background: #3498db;\n",
    "            color: white;\n",
    "            font-weight: 600;\n",
    "        }}\n",
    "        .data-table tr:nth-child(even) {{\n",
    "            background: #f8f9fa;\n",
    "        }}\n",
    "        .data-table tr:hover {{\n",
    "            background: #e8f4f8;\n",
    "        }}\n",
    "        \n",
    "        /* Chart */\n",
    "        .chart-container {{\n",
    "            text-align: center;\n",
    "            margin: 24px 0;\n",
    "        }}\n",
    "        .chart-container img {{\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "            border: 1px solid #ddd;\n",
    "            border-radius: 4px;\n",
    "        }}\n",
    "        \n",
    "        /* Footer */\n",
    "        .footer {{\n",
    "            margin-top: 40px;\n",
    "            padding-top: 20px;\n",
    "            border-top: 1px solid #eee;\n",
    "            color: #95a5a6;\n",
    "            font-size: 0.85em;\n",
    "            text-align: center;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>{title}</h1>\n",
    "        <p class=\"meta\">\n",
    "            üìÖ Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>\n",
    "            üêç Python {sys.version.split()[0]} | Pandas {pd.__version__}\n",
    "        </p>\n",
    "        \n",
    "        <h2>üìä Key Performance Indicators</h2>\n",
    "        {df_to_html_table(kpis, max_rows=20)}\n",
    "        \n",
    "        <h2>üìà Revenue by Channel</h2>\n",
    "        {df_to_html_table(by_channel, max_rows=20)}\n",
    "        \n",
    "        <h2>üì¶ Revenue by Product</h2>\n",
    "        {df_to_html_table(by_product, max_rows=20)}\n",
    "        \n",
    "        <h2>üìâ Daily Revenue Trend</h2>\n",
    "        <div class=\"chart-container\">\n",
    "            <img src=\"{chart_file}\" alt=\"Daily Revenue Chart\">\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"footer\">\n",
    "            Report generated by Automated Analytics Pipeline | Chapter 12 Demo\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "    \n",
    "    report_path.write_text(html, encoding=\"utf-8\")\n",
    "    print(f\"‚úÖ HTML report saved to: {report_path}\")\n",
    "    return report_path\n",
    "\n",
    "\n",
    "# Generate the HTML report\n",
    "html_path = export_html_report(\n",
    "    OUTPUT_ROOT,\n",
    "    title=f\"Sales Report ({REPORT_REGION}, last {DAYS_LOOKBACK} days)\",\n",
    "    kpis=kpis,\n",
    "    by_channel=breakdowns[\"by_channel\"],\n",
    "    by_product=breakdowns[\"by_product\"],\n",
    "    chart_file=chart_path.name,\n",
    ")\n",
    "\n",
    "print(f\"\\nüìÅ Open this file in your browser to view the report:\")\n",
    "print(f\"   {html_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca749edc",
   "metadata": {},
   "source": [
    "### üéØ Mini-Exercise 2: Customize the HTML Report\n",
    "\n",
    "Modify the `export_html_report` function to add one of the following:\n",
    "\n",
    "1. Add a **summary paragraph** that says how many orders and total revenue\n",
    "2. Change the **color scheme** (try different hex colors for headers)\n",
    "3. Add the **daily breakdown table** to the report\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint for option 1</summary>\n",
    "\n",
    "Add this before the KPI table:\n",
    "```python\n",
    "summary = f\"<p><strong>Summary:</strong> {len(report_df)} orders totaling ${report_df['revenue'].sum():,.2f}</p>\"\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53fb9e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.9 PDF Export Options\n",
    "\n",
    "### Why PDF?\n",
    "\n",
    "PDF (Portable Document Format) is ideal for:\n",
    "- üìÑ **Formal reports** that need to look professional\n",
    "- üñ®Ô∏è **Printing** with consistent formatting\n",
    "- üìß **Email attachments** that won't change appearance\n",
    "\n",
    "### PDF Generation Options in Python\n",
    "\n",
    "Generating PDFs from Python requires additional libraries. Here are the main options:\n",
    "\n",
    "| Library | Approach | Difficulty | Best For |\n",
    "|---------|----------|------------|----------|\n",
    "| **weasyprint** | HTML ‚Üí PDF | Medium | Converting HTML reports to PDF |\n",
    "| **reportlab** | Build PDF directly | Hard | Complex custom layouts |\n",
    "| **fpdf2** | Simple PDF creation | Easy | Basic reports |\n",
    "| **pdfkit** | HTML ‚Üí PDF (uses wkhtmltopdf) | Easy | Quick conversions |\n",
    "\n",
    "> ‚ö†Ô∏è **Note:** PDF libraries often have system dependencies (fonts, wkhtmltopdf binary). For beginners, we recommend starting with HTML reports and converting to PDF manually (print ‚Üí Save as PDF) or using an online converter.\n",
    "\n",
    "### Example: Simple PDF with fpdf2\n",
    "\n",
    "Here's a conceptual example (uncomment and install `fpdf2` to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Export Example (conceptual - requires fpdf2: pip install fpdf2)\n",
    "# Uncomment the code below to try it\n",
    "\n",
    "# from fpdf import FPDF\n",
    "#\n",
    "# def export_simple_pdf(out_path: Path, title: str, kpis: pd.DataFrame) -> Path:\n",
    "#     \"\"\"Generate a simple PDF report.\"\"\"\n",
    "#     pdf = FPDF()\n",
    "#     pdf.add_page()\n",
    "#     \n",
    "#     # Title\n",
    "#     pdf.set_font(\"Arial\", \"B\", 16)\n",
    "#     pdf.cell(0, 10, title, ln=True, align=\"C\")\n",
    "#     pdf.ln(10)\n",
    "#     \n",
    "#     # KPIs\n",
    "#     pdf.set_font(\"Arial\", \"B\", 12)\n",
    "#     pdf.cell(0, 10, \"Key Performance Indicators\", ln=True)\n",
    "#     \n",
    "#     pdf.set_font(\"Arial\", \"\", 10)\n",
    "#     for _, row in kpis.iterrows():\n",
    "#         pdf.cell(0, 8, f\"{row['metric']}: {row['value']:.2f}\", ln=True)\n",
    "#     \n",
    "#     pdf.output(str(out_path))\n",
    "#     return out_path\n",
    "#\n",
    "# # Generate PDF\n",
    "# pdf_path = OUTPUT_ROOT / \"report.pdf\"\n",
    "# export_simple_pdf(pdf_path, \"Sales Report\", kpis)\n",
    "\n",
    "print(\"üí° PDF export requires additional libraries.\")\n",
    "print(\"   For now, open the HTML report in a browser and use Print ‚Üí Save as PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409c2d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.10 Reproducibility: Capturing Run Metadata\n",
    "\n",
    "### What is Reproducibility?\n",
    "\n",
    "**Reproducibility** means being able to recreate your exact results at any time. This requires recording:\n",
    "\n",
    "1. **What parameters were used** ‚Äî Region, date range, filters\n",
    "2. **When the analysis ran** ‚Äî Timestamp\n",
    "3. **What environment was used** ‚Äî Python version, library versions\n",
    "4. **What data was used** ‚Äî Data source, row counts, checksums\n",
    "\n",
    "### Why Metadata Matters\n",
    "\n",
    "Imagine this scenario:\n",
    "> \"The sales report from last month shows different numbers than today's report for the same period. Why?\"\n",
    "\n",
    "Without metadata, you'd have to guess. With metadata, you can check:\n",
    "- Were the parameters the same?\n",
    "- Was the data source updated?\n",
    "- Did library versions change?\n",
    "\n",
    "### Creating a Metadata Capture Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_run_metadata(params: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Capture metadata about the current run for reproducibility.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    params : dict\n",
    "        Dictionary of parameters used in this run\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Single-row DataFrame with metadata\n",
    "    \"\"\"\n",
    "    def safe_version(mod_name: str) -> str:\n",
    "        \"\"\"Safely get a module's version, or 'not-installed' if unavailable.\"\"\"\n",
    "        try:\n",
    "            mod = __import__(mod_name)\n",
    "            return getattr(mod, \"__version__\", \"unknown\")\n",
    "        except Exception:\n",
    "            return \"not-installed\"\n",
    "    \n",
    "    # Collect all metadata\n",
    "    meta = {\n",
    "        # When\n",
    "        \"run_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \n",
    "        # Environment\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"pandas\": safe_version(\"pandas\"),\n",
    "        \"numpy\": safe_version(\"numpy\"),\n",
    "        \"matplotlib\": safe_version(\"matplotlib\"),\n",
    "        \n",
    "        # Parameters (stored as JSON string)\n",
    "        \"params\": json.dumps(params, ensure_ascii=False),\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([meta])\n",
    "\n",
    "\n",
    "# Capture metadata for this run\n",
    "metadata = capture_run_metadata({\n",
    "    \"region\": REPORT_REGION,\n",
    "    \"days_lookback\": DAYS_LOOKBACK\n",
    "})\n",
    "\n",
    "print(\"Run Metadata:\")\n",
    "print(\"-\" * 60)\n",
    "for col in metadata.columns:\n",
    "    print(f\"{col:15s}: {metadata[col].values[0]}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52accbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata to a file\n",
    "metadata_path = OUTPUT_ROOT / \"run_metadata.csv\"\n",
    "metadata.to_csv(metadata_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Metadata saved to: {metadata_path}\")\n",
    "print(\"\\nüí° Tip: Append each run's metadata to build a history of all runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68401fbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.11 Version Control with Git\n",
    "\n",
    "### What is Version Control?\n",
    "\n",
    "**Version control** is a system that tracks changes to files over time. Think of it like \"Track Changes\" in Word, but for your entire project.\n",
    "\n",
    "**Git** is the most popular version control system. It allows you to:\n",
    "- üìú **Track history** ‚Äî See every change ever made\n",
    "- ‚Ü©Ô∏è **Undo mistakes** ‚Äî Revert to previous versions\n",
    "- üåø **Branch** ‚Äî Work on new features without breaking existing code\n",
    "- üë• **Collaborate** ‚Äî Multiple people can work on the same project\n",
    "\n",
    "### Why Version Control Matters for Data Analysis\n",
    "\n",
    "As a data analyst, version control helps you:\n",
    "1. **Explain changes** ‚Äî \"Why did the numbers change?\" ‚Üí Check the commit history\n",
    "2. **Reproduce results** ‚Äî Go back to the exact code that generated a report\n",
    "3. **Experiment safely** ‚Äî Try new approaches without losing working code\n",
    "4. **Collaborate** ‚Äî Share analysis with teammates\n",
    "\n",
    "### Essential Git Commands\n",
    "\n",
    "Here are the most important Git commands for beginners:\n",
    "\n",
    "| Command | Purpose | Example |\n",
    "|---------|---------|---------|\n",
    "| `git init` | Create a new repository | `git init` |\n",
    "| `git status` | See what's changed | `git status` |\n",
    "| `git add` | Stage changes for commit | `git add analysis.py` |\n",
    "| `git commit` | Save a snapshot | `git commit -m \"Add sales report\"` |\n",
    "| `git log` | View history | `git log --oneline` |\n",
    "| `git diff` | See what changed | `git diff analysis.py` |\n",
    "\n",
    "### Git Workflow for Analysis Projects\n",
    "\n",
    "```\n",
    "1. Make changes to your code\n",
    "2. git add <files>       # Stage your changes\n",
    "3. git commit -m \"...\"   # Save with a message\n",
    "4. Repeat!\n",
    "```\n",
    "\n",
    "> üí° **Tip:** Commit often with descriptive messages. Instead of \"updated code\", write \"Add regional filter to sales report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be170e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run Git commands from Python using subprocess\n",
    "# Here's how to capture the current Git commit hash for reproducibility\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def get_git_info() -> dict:\n",
    "    \"\"\"\n",
    "    Get current Git repository information for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with commit_hash, branch, and status\n",
    "    \"\"\"\n",
    "    info = {\n",
    "        \"commit_hash\": \"not-in-git-repo\",\n",
    "        \"branch\": \"unknown\",\n",
    "        \"has_uncommitted_changes\": None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Get current commit hash\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"rev-parse\", \"HEAD\"],\n",
    "            capture_output=True, text=True, timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            info[\"commit_hash\"] = result.stdout.strip()[:8]  # Short hash\n",
    "        \n",
    "        # Get current branch\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"branch\", \"--show-current\"],\n",
    "            capture_output=True, text=True, timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            info[\"branch\"] = result.stdout.strip()\n",
    "        \n",
    "        # Check for uncommitted changes\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\"],\n",
    "            capture_output=True, text=True, timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            info[\"has_uncommitted_changes\"] = len(result.stdout.strip()) > 0\n",
    "            \n",
    "    except Exception as e:\n",
    "        info[\"error\"] = str(e)\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "# Try to get Git info (will show placeholder if not in a Git repo)\n",
    "git_info = get_git_info()\n",
    "print(\"Git Repository Info:\")\n",
    "for key, value in git_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e47c2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.12 Documentation and Code Readability\n",
    "\n",
    "### Why Documentation Matters\n",
    "\n",
    "> \"Code is read far more often than it is written.\" ‚Äî Guido van Rossum (creator of Python)\n",
    "\n",
    "Good documentation helps:\n",
    "- **Your future self** ‚Äî You will forget why you wrote something\n",
    "- **Your teammates** ‚Äî Others need to understand and use your code\n",
    "- **Your stakeholders** ‚Äî Non-technical people may read your analysis\n",
    "\n",
    "### Types of Documentation\n",
    "\n",
    "1. **Code comments** ‚Äî Explain *why*, not *what*\n",
    "2. **Docstrings** ‚Äî Describe what functions do\n",
    "3. **README files** ‚Äî Project overview and setup instructions\n",
    "4. **Inline explanations** ‚Äî Markdown cells in notebooks\n",
    "\n",
    "### Best Practices for Readable Code\n",
    "\n",
    "#### 1. Use Descriptive Names\n",
    "\n",
    "```python\n",
    "# ‚ùå Bad\n",
    "x = df[df['d'] > '2024-01-01']\n",
    "\n",
    "# ‚úÖ Good  \n",
    "recent_sales = sales[sales['date'] > '2024-01-01']\n",
    "```\n",
    "\n",
    "#### 2. Write Helpful Comments\n",
    "\n",
    "```python\n",
    "# ‚ùå Bad - describes WHAT (obvious from code)\n",
    "# Add 1 to x\n",
    "x = x + 1\n",
    "\n",
    "# ‚úÖ Good - explains WHY\n",
    "# Shift to 1-based indexing for user display\n",
    "display_index = index + 1\n",
    "```\n",
    "\n",
    "#### 3. Use Docstrings for Functions\n",
    "\n",
    "```python\n",
    "def calculate_roi(revenue: float, cost: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Return on Investment.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    revenue : float\n",
    "        Total revenue generated\n",
    "    cost : float\n",
    "        Total cost of investment\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        ROI as a decimal (0.5 = 50% return)\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    >>> calculate_roi(150, 100)\n",
    "    0.5\n",
    "    \"\"\"\n",
    "    return (revenue - cost) / cost\n",
    "```\n",
    "\n",
    "#### 4. Keep Functions Small and Focused\n",
    "\n",
    "Each function should do **one thing well**. If a function is longer than 20-30 lines, consider splitting it.\n",
    "\n",
    "#### 5. Use Type Hints\n",
    "\n",
    "Type hints make your code self-documenting:\n",
    "\n",
    "```python\n",
    "# Without hints - unclear what types are expected\n",
    "def process(data, threshold):\n",
    "    ...\n",
    "\n",
    "# With hints - clear expectations\n",
    "def process(data: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Good vs Bad Documentation\n",
    "\n",
    "# ‚ùå BAD: Undocumented, cryptic names\n",
    "def proc(d, t):\n",
    "    return d[d['v'] > t]\n",
    "\n",
    "\n",
    "# ‚úÖ GOOD: Clear names, docstring, type hints\n",
    "def filter_by_threshold(\n",
    "    data: pd.DataFrame, \n",
    "    threshold: float,\n",
    "    value_column: str = \"value\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter DataFrame to rows where a column exceeds a threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        Input data to filter\n",
    "    threshold : float\n",
    "        Minimum value to include (exclusive)\n",
    "    value_column : str\n",
    "        Name of the column to check (default: \"value\")\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Filtered data with only rows exceeding threshold\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    >>> df = pd.DataFrame({'value': [1, 5, 10]})\n",
    "    >>> filter_by_threshold(df, 3)\n",
    "       value\n",
    "    1      5\n",
    "    2     10\n",
    "    \"\"\"\n",
    "    return data[data[value_column] > threshold].copy()\n",
    "\n",
    "\n",
    "# Demonstrate the well-documented function\n",
    "sample_df = pd.DataFrame({\"value\": [10, 25, 5, 30, 15]})\n",
    "result = filter_by_threshold(sample_df, threshold=12)\n",
    "print(\"Filtered result (values > 12):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de848ce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.13 Complete Pipeline: One Function to Run Everything\n",
    "\n",
    "### The Goal\n",
    "\n",
    "Create a **single function** that generates all outputs into a timestamped folder. This makes it easy to:\n",
    "- Run the same analysis repeatedly without overwriting results\n",
    "- Schedule as an automated job\n",
    "- Compare outputs from different runs\n",
    "\n",
    "### Design Decisions\n",
    "\n",
    "1. **Timestamped folders** ‚Äî Each run gets its own folder (`run_20240115_093045/`)\n",
    "2. **Return a result object** ‚Äî The function returns paths to all generated files\n",
    "3. **Parameters as arguments** ‚Äî Easy to customize without editing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ReportResult:\n",
    "    \"\"\"\n",
    "    Container for all outputs from a report run.\n",
    "    \n",
    "    Using a dataclass makes it easy to access results by name\n",
    "    and ensures immutability (frozen=True prevents modification).\n",
    "    \"\"\"\n",
    "    run_dir: Path           # Directory containing all outputs\n",
    "    chart_path: Path        # Path to the saved chart PNG\n",
    "    html_path: Path         # Path to the HTML report\n",
    "    exports: list[Path]     # List of exported data files\n",
    "    metadata_path: Path     # Path to run metadata CSV\n",
    "\n",
    "\n",
    "def run_report(\n",
    "    region: str = \"ALL\",\n",
    "    days_lookback: int = 30,\n",
    "    seed: int = 42\n",
    ") -> ReportResult:\n",
    "    \"\"\"\n",
    "    Execute the complete analysis pipeline and generate all outputs.\n",
    "    \n",
    "    This is the main entry point for the automated report. It:\n",
    "    1. Loads data from seaborn's taxis dataset\n",
    "    2. Cleans and filters based on parameters\n",
    "    3. Calculates KPIs and breakdowns\n",
    "    4. Saves charts, exports, and HTML report\n",
    "    5. Records metadata for reproducibility\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    region : str\n",
    "        Region to filter by, or \"ALL\" for all regions\n",
    "    days_lookback : int\n",
    "        Number of recent days to include\n",
    "    seed : int\n",
    "        Random seed for reproducibility (used in data transformation)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    ReportResult\n",
    "        Dataclass containing paths to all generated outputs\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"RUNNING AUTOMATED SALES REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Region: {region}\")\n",
    "    print(f\"Days Lookback: {days_lookback}\")\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create a unique folder for this run using timestamp\n",
    "    run_stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = OUTPUT_ROOT / f\"run_{run_stamp}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\nüìÅ Output directory: {run_dir}\")\n",
    "    \n",
    "    # Step 1: Load data from seaborn taxis dataset\n",
    "    print(\"\\n[1/6] Loading data from seaborn taxis dataset...\")\n",
    "    raw = load_sales_data()\n",
    "    \n",
    "    # Step 2: Clean data\n",
    "    print(\"\\n[2/6] Cleaning data...\")\n",
    "    sales = clean_sales_data(raw)\n",
    "    \n",
    "    # Step 3: Filter based on parameters\n",
    "    print(\"\\n[3/6] Filtering data...\")\n",
    "    report_df = filter_for_report(sales, region, days_lookback)\n",
    "    \n",
    "    # Step 4: Calculate KPIs and breakdowns\n",
    "    print(\"\\n[4/6] Calculating KPIs...\")\n",
    "    kpis = kpi_summary(report_df)\n",
    "    breakdowns = top_breakdowns(report_df)\n",
    "    \n",
    "    # Step 5: Generate outputs\n",
    "    print(\"\\n[5/6] Generating outputs...\")\n",
    "    \n",
    "    # Save chart\n",
    "    chart_path = run_dir / \"daily_revenue.png\"\n",
    "    save_daily_revenue_plot(breakdowns[\"by_day\"], chart_path)\n",
    "    \n",
    "    # Export data files\n",
    "    exports = export_excel_or_csv(run_dir, report_df, kpis, breakdowns)\n",
    "    \n",
    "    # Generate HTML report\n",
    "    html_path = export_html_report(\n",
    "        run_dir,\n",
    "        title=f\"Sales Report ({region}, last {days_lookback} days)\",\n",
    "        kpis=kpis,\n",
    "        by_channel=breakdowns[\"by_channel\"],\n",
    "        by_product=breakdowns[\"by_product\"],\n",
    "        chart_file=chart_path.name,\n",
    "    )\n",
    "    \n",
    "    # Step 6: Save metadata\n",
    "    print(\"\\n[6/6] Saving metadata...\")\n",
    "    metadata = capture_run_metadata({\n",
    "        \"region\": region,\n",
    "        \"days_lookback\": days_lookback,\n",
    "        \"seed\": seed,\n",
    "        \"row_count\": len(report_df),\n",
    "        \"total_revenue\": float(report_df[\"revenue\"].sum()),\n",
    "    })\n",
    "    metadata_path = run_dir / \"run_metadata.csv\"\n",
    "    metadata.to_csv(metadata_path, index=False)\n",
    "    print(f\"‚úÖ Metadata saved: {metadata_path.name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ REPORT COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return ReportResult(\n",
    "        run_dir=run_dir,\n",
    "        chart_path=chart_path,\n",
    "        html_path=html_path,\n",
    "        exports=exports,\n",
    "        metadata_path=metadata_path,\n",
    "    )\n",
    "\n",
    "\n",
    "# Run the complete pipeline\n",
    "result = run_report(region=REPORT_REGION, days_lookback=DAYS_LOOKBACK, seed=42)\n",
    "\n",
    "# Show all generated files\n",
    "print(\"\\nüìã Generated Files:\")\n",
    "for file in result.run_dir.iterdir():\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f\"   üìÑ {file.name} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaaae87",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.14 Scheduling Analytics Tasks\n",
    "\n",
    "### Why Scheduling?\n",
    "\n",
    "Scheduling allows you to run reports automatically:\n",
    "- üìÖ **Daily reports** ‚Äî Fresh data every morning\n",
    "- üìÜ **Weekly summaries** ‚Äî Monday briefings\n",
    "- üåô **Overnight processing** ‚Äî Heavy computations while you sleep\n",
    "\n",
    "### Scheduling Options\n",
    "\n",
    "#### Windows: Task Scheduler\n",
    "\n",
    "Windows Task Scheduler can run Python scripts on a schedule.\n",
    "\n",
    "**Steps:**\n",
    "1. Export your analysis to a `.py` script (see next section)\n",
    "2. Open Task Scheduler (search \"Task Scheduler\" in Start menu)\n",
    "3. Create a new task with:\n",
    "   - Trigger: Daily at 7:00 AM\n",
    "   - Action: Run your Python script\n",
    "\n",
    "#### macOS/Linux: Cron\n",
    "\n",
    "Cron is the Unix scheduler. Edit with `crontab -e`:\n",
    "\n",
    "```bash\n",
    "# Run every day at 7 AM\n",
    "0 7 * * * /path/to/python /path/to/report_script.py\n",
    "```\n",
    "\n",
    "#### Cloud Options\n",
    "\n",
    "For production systems, consider:\n",
    "- **GitHub Actions** ‚Äî Free for public repos\n",
    "- **AWS Lambda** + CloudWatch ‚Äî Serverless scheduling\n",
    "- **Apache Airflow** ‚Äî Complex pipeline orchestration\n",
    "\n",
    "### Best Practices for Scheduled Scripts\n",
    "\n",
    "1. **Use absolute paths** ‚Äî Scheduled tasks run from unknown directories\n",
    "2. **Log errors** ‚Äî Write errors to a log file for debugging\n",
    "3. **Use timestamped folders** ‚Äî Don't overwrite previous runs\n",
    "4. **Send notifications** ‚Äî Email on success/failure\n",
    "5. **Test manually first** ‚Äî Run the script by hand before scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2589c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Converting this notebook to a schedulable script\n",
    "# The code below shows what a production script might look like\n",
    "\n",
    "SCRIPT_TEMPLATE = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Automated Sales Report Generator\n",
    "\n",
    "This script generates a sales report and can be scheduled to run automatically.\n",
    "Usage: python report_script.py --region North --days 30\n",
    "\n",
    "Author: Your Name\n",
    "Date: 2024-01-01\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging\n",
    "LOG_DIR = Path(\"logs\")\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    filename=LOG_DIR / f\"report_{datetime.now():%Y%m%d}.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def main():\n",
    "    # Parse command-line arguments\n",
    "    parser = argparse.ArgumentParser(description=\"Generate sales report\")\n",
    "    parser.add_argument(\"--region\", default=\"ALL\", help=\"Region to filter\")\n",
    "    parser.add_argument(\"--days\", type=int, default=30, help=\"Days lookback\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    logging.info(f\"Starting report: region={args.region}, days={args.days}\")\n",
    "    \n",
    "    try:\n",
    "        # Your report code here...\n",
    "        # result = run_report(region=args.region, days_lookback=args.days)\n",
    "        logging.info(\"Report completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Report failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "print(\"Example Script Template:\")\n",
    "print(\"-\" * 60)\n",
    "print(SCRIPT_TEMPLATE[:800] + \"...\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nüí° Save this template as 'report_script.py' and customize for your needs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeda468",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12.15 Exercises\n",
    "\n",
    "### Exercise 1: Change Parameters\n",
    "Set `REPORT_REGION = \"ALL\"` at the top of this notebook and rerun the complete pipeline. \n",
    "- How do the KPIs change?\n",
    "- How many more rows are in the filtered data?\n",
    "\n",
    "### Exercise 2: Add a New Breakdown\n",
    "Modify the `top_breakdowns()` function to add a breakdown by `region` (useful when REPORT_REGION is \"ALL\").\n",
    "- Add `by_region` to the returned dictionary\n",
    "- Update the HTML report to include this new table\n",
    "\n",
    "### Exercise 3: Add a New KPI\n",
    "Add `median_order_value` to the `kpi_summary()` function.\n",
    "- Hint: Use `df[\"revenue\"].median()`\n",
    "- Why might median be better than mean for order values?\n",
    "\n",
    "### Exercise 4: Improve Missing Value Handling\n",
    "The current cleaning function fills missing prices with the overall median. Improve it to use the **product-specific median** instead.\n",
    "- Hint: Use `groupby('product')['unit_price'].transform('median')`\n",
    "\n",
    "### Exercise 5: Add Git Commit to Metadata\n",
    "Modify the `capture_run_metadata()` function to include the Git commit hash (use the `get_git_info()` function we created).\n",
    "\n",
    "### Mini-Project: Create a Standalone Script\n",
    "Convert this notebook into a Python script (`chapter12_report.py`) that:\n",
    "1. Accepts command-line arguments for region and days_lookback\n",
    "2. Logs progress to a file\n",
    "3. Sends an email notification when complete (advanced)\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hints for the Mini-Project</summary>\n",
    "\n",
    "```python\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--region\", default=\"ALL\")\n",
    "parser.add_argument(\"--days\", type=int, default=30)\n",
    "args = parser.parse_args()\n",
    "\n",
    "result = run_report(region=args.region, days_lookback=args.days)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf7fef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "In this chapter, you learned how to transform manual, one-off analyses into **automated, reproducible pipelines**.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | What It Means | Why It Matters |\n",
    "|---------|---------------|----------------|\n",
    "| **Automation** | Using functions and code to perform repetitive tasks | Saves time, reduces errors, enables scale |\n",
    "| **Parameterization** | Defining inputs at the top, not scattered in code | Easy to change, clear documentation |\n",
    "| **Exporting** | Saving results as files (CSV, Excel, HTML, PDF) | Shareable deliverables, historical records |\n",
    "| **Reproducibility** | Recording metadata so results can be recreated | Trust, collaboration, debugging |\n",
    "| **Version Control** | Tracking code changes with Git | History, undo, collaboration |\n",
    "| **Documentation** | Explaining code with comments and docstrings | Future you, teammates, stakeholders |\n",
    "| **Scheduling** | Running scripts automatically at set times | Daily reports, overnight processing |\n",
    "\n",
    "### Best Practices Checklist\n",
    "\n",
    "‚úÖ **Automation**\n",
    "- [ ] Wrap analysis steps in reusable functions\n",
    "- [ ] Use a single \"main\" function for the complete pipeline\n",
    "- [ ] Return structured results (dataclasses, dictionaries)\n",
    "\n",
    "‚úÖ **Parameterization**\n",
    "- [ ] Define all configurable values at the top\n",
    "- [ ] Use descriptive parameter names\n",
    "- [ ] Support command-line arguments for scripts\n",
    "\n",
    "‚úÖ **Exporting**\n",
    "- [ ] Save outputs to a dedicated folder (not mixed with source code)\n",
    "- [ ] Use timestamped folders for multiple runs\n",
    "- [ ] Export in formats your stakeholders need (Excel, HTML, PDF)\n",
    "\n",
    "‚úÖ **Reproducibility**\n",
    "- [ ] Record run timestamp and parameters\n",
    "- [ ] Include Python and library versions\n",
    "- [ ] Track Git commit hash when available\n",
    "\n",
    "‚úÖ **Documentation**\n",
    "- [ ] Write docstrings for all functions\n",
    "- [ ] Use meaningful variable names\n",
    "- [ ] Add type hints for clarity\n",
    "\n",
    "### The Automation Mindset\n",
    "\n",
    "> \"If you do something more than twice, automate it.\"\n",
    "\n",
    "Start thinking about your analysis as a **pipeline**, not a one-time script:\n",
    "\n",
    "```\n",
    "Data ‚Üí Clean ‚Üí Analyze ‚Üí Visualize ‚Üí Report ‚Üí Share\n",
    "  ‚îÇ        ‚îÇ        ‚îÇ          ‚îÇ         ‚îÇ\n",
    "  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "           All reusable, all automated\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b85cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "### Official Documentation\n",
    "\n",
    "- **Pandas I/O (CSV/Excel):** https://pandas.pydata.org/docs/user_guide/io.html\n",
    "- **Pandas GroupBy:** https://pandas.pydata.org/docs/user_guide/groupby.html\n",
    "- **Matplotlib Saving Figures:** https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html\n",
    "- **Python pathlib:** https://docs.python.org/3/library/pathlib.html\n",
    "\n",
    "### Version Control\n",
    "\n",
    "- **Git Handbook (GitHub):** https://guides.github.com/introduction/git-handbook/\n",
    "- **Git Tutorial (Atlassian):** https://www.atlassian.com/git/tutorials\n",
    "- **Interactive Git Learning:** https://learngitbranching.js.org/\n",
    "\n",
    "### Scheduling\n",
    "\n",
    "- **Windows Task Scheduler:** https://learn.microsoft.com/windows/win32/taskschd/task-scheduler-start-page\n",
    "- **Cron Tutorial:** https://crontab.guru/\n",
    "- **GitHub Actions for Scheduling:** https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule\n",
    "\n",
    "### Reproducibility\n",
    "\n",
    "- **The Turing Way (Reproducible Research):** https://the-turing-way.netlify.app/reproducible-research/reproducible-research.html\n",
    "- **Cookiecutter Data Science:** https://drivendata.github.io/cookiecutter-data-science/\n",
    "\n",
    "### PDF Generation (Advanced)\n",
    "\n",
    "- **fpdf2 Documentation:** https://pyfpdf.github.io/fpdf2/\n",
    "- **WeasyPrint (HTML to PDF):** https://weasyprint.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec424d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## End of Chapter 12\n",
    "\n",
    "üéâ **Congratulations!** You've learned how to build automated, reproducible analysis pipelines.\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Part B** of this book, we'll apply these skills to real-world data analytics projects, starting with:\n",
    "- **Chapter 13:** Problem Definition and Analytical Frameworks\n",
    "- **Chapter 14:** Data Collection, Integration, and Understanding\n",
    "\n",
    "### Try This\n",
    "\n",
    "1. Run the complete pipeline with different parameters\n",
    "2. Open the generated HTML report in your browser\n",
    "3. Explore the output files in the `outputs/chapter_12/` folder\n",
    "\n",
    "---\n",
    "\n",
    "*\"The best code is code you don't have to run manually.\"*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
